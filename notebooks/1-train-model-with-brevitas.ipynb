{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ed853b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from quantized_deep4 import QuantDeep4Net\n",
    "from braindecode.torch_ext.optimizers import AdamW\n",
    "from braindecode.torch_ext.util import set_random_seeds\n",
    "from brevitas.export import export_qonnx\n",
    "from qonnx.util.cleanup import cleanup as qonnx_cleanup\n",
    "from qonnx.core.modelwrapper import ModelWrapper\n",
    "from finn.transformation.qonnx.convert_qonnx_to_finn import ConvertQONNXtoFINN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb67e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Fake, learnable within-subject data (N,C,T,1) = (400,62,1000,1) ---\n",
    "rng = np.random.default_rng(42)\n",
    "N, C, T = 400, 62, 1000\n",
    "\n",
    "# Base noise\n",
    "X = rng.normal(0, 1, size=(N, C, T, 1)).astype(np.float32)\n",
    "\n",
    "# Balanced labels\n",
    "Y = np.concatenate([np.zeros(N//2, dtype=np.int64), np.ones(N - N//2, dtype=np.int64)])\n",
    "rng.shuffle(Y)\n",
    "\n",
    "# Make class 1 slightly structured so the model can learn:\n",
    "# add a faint sinusoid to first 5 channels for class-1 trials\n",
    "t = np.linspace(0, 1, T, dtype=np.float32)\n",
    "sinusoid = (0.25 * np.sin(2 * np.pi * 8 * t))  # 8 Hz bump\n",
    "mask = (Y == 1)\n",
    "X[mask, 0:5, :, 0] += sinusoid  # broadcast over time, first 5 chans\n",
    "\n",
    "# Optional: light per-channel standardization (keeps signal learnable)\n",
    "mean = X.mean(axis=(0,2,3), keepdims=True)\n",
    "std  = X.std(axis=(0,2,3), keepdims=True) + 1e-6\n",
    "X = ((X - mean) / std).astype(np.float32)\n",
    "\n",
    "# Hand back like your original get_data() call would\n",
    "# X, Y now match what your code expects:\n",
    "#   X.shape == (N, 62, 1000, 1)\n",
    "#   Y.shape == (N,)\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784a92a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = X[50:250], Y[50:250]\n",
    "X_val, Y_val = X[250:300], Y[250:300]\n",
    "X_test, Y_test = X[300:], Y[300:]\n",
    "\n",
    "n_classes = 2\n",
    "in_chans = X.shape[1]\n",
    "\n",
    "# final_conv_length = auto ensures we only get a single output in the time dimension\n",
    "model = QuantDeep4Net(in_chans=in_chans, n_classes=n_classes,\n",
    "                 input_time_length=X.shape[2],\n",
    "                 final_conv_length=1, split_first_layer=False, quant_bit_width=2)#.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a0b0e0-304d-40f4-92fb-e6479b4a77fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the network so parameters exist\n",
    "net = model.create_network()\n",
    "\n",
    "# Count parameters\n",
    "num_params = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "print(f\"Trainable parameters: {num_params:,}\")\n",
    "\n",
    "# If you also want frozen ones:\n",
    "total_params = sum(p.numel() for p in net.parameters())\n",
    "print(f\"Total parameters (incl. frozen): {total_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef07a06-8faf-4aea-a004-3e92a97126fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# these are good values for the deep model\n",
    "optimizer = AdamW(model.parameters(), lr=1 * 0.01, weight_decay=0.5*0.001)\n",
    "model.compile(loss=F.nll_loss, optimizer=optimizer, iterator_seed=1, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffde4ed3-8a87-4f45-90b6-3db0c3ee46c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, Y_train, epochs=10, batch_size=16, scheduler='cosine', \n",
    "        validation_data=(X_val, Y_val))#, remember_best_column='valid_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06b9852",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = model.evaluate(X_test, Y_test)\n",
    "print(test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3adfa3-db51-44e1-a9de-e94391371449",
   "metadata": {},
   "outputs": [],
   "source": [
    "ready_model_filename = \"model.onnx\"\n",
    "\n",
    "# CPU + eval + dummy input\n",
    "model.network.cpu().eval()\n",
    "input_t = torch.randn(1, 62, 1000, 1)\n",
    "\n",
    "# Export → clean\n",
    "export_qonnx(model.network, export_path=ready_model_filename, input_t=input_t)\n",
    "qonnx_cleanup(ready_model_filename, out_file=ready_model_filename)\n",
    "\n",
    "# Convert QONNX → FINN (no explicit dtype needed)\n",
    "mw = ModelWrapper(ready_model_filename)\n",
    "mw = mw.transform(ConvertQONNXtoFINN())\n",
    "mw.save(ready_model_filename)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
